{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns1-eK2JeUcB",
        "outputId": "44642d2f-2cf2-48c0-aa4c-e56ab59cc522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.36.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.36.0 watchdog-4.0.1\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.9)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.81)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.36.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "# install all necessary libraries\n",
        "\n",
        "!pip install streamlit\n",
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install streamlit\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru_dH-7ReDPP",
        "outputId": "c099e865-337d-473a-cbb9-7aa3117fc560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14 \n",
            "\n",
            "4 C. Brito et al.\n",
            "data [20, 9]. They provide a secure memory space at each server, where genomic\n",
            "data can be securely processed in plaintext format. Both external and internal\n",
            "attackers, even with high Operating System (OS) privileges, cannot access this\n",
            "protected region and disclose the data being processed. While this is a promising\n",
            "technology for running GWAS securely, its application has been typically limited\n",
            "to a single-server mode [5, 18, 32]. By taking advantage of distributed infrastruc-\n",
            "tures, it is possible to enhance the speed and scalability (i.e., the amount of data\n",
            "being analyzed) of GWASes. However, as highlighted in this paper, developing a\n",
            "distributed solution for privacy-preserving GWAS requires a fundamentally new\n",
            "design that differs from previous methodologies. Namely, it requires securing\n",
            "both the computation and storage of data at each cluster server and the data\n",
            "being exchanged across servers.\n",
            "Our Contributions We propose Gyosa, a novel distributed and privacy-\n",
            "preserving framework for securely executing GWAS in untrusted distributed\n",
            "infrastructures. Gyosa is built on top of Apache Spark [38], a distributed com-\n",
            "putation framework, and uses Glow, a library for genomic processing that in-\n",
            "cludes regression-based algorithms, statistical tests, and population stratification\n",
            "methods to perform GWAS easily [13]. These are combined with TEEs, namely\n",
            "Intel SGX, to provide a secure environment where sensitive genomic information\n",
            "can be efficiently processed in plaintext without disclosing it to internal or exter-\n",
            "nal attackers. Our approach distinguishes itself from recent proposals such [39,\n",
            "20], as it promotes the outsourcing of computation in a distributed manner in\n",
            "untrusted third-party entities. Also, by resorting to Glow, Gyosa allows the ex-\n",
            "tension of the current genomic analysis pipeline, in which one can add new tasks\n",
            "(e.g., new statistical tests, genomic imputation, and querying). Expanding on\n",
            "our previous work [2], our solution enables fine-grained differentiation between\n",
            "sensitive and nonsensitive information processed by GWAS. By securely offload-\n",
            "ing sensitive information to TEEs, we show that it is possible to run large-scale\n",
            "GWAS-based algorithms while protecting the confidentiality of critical data.\n",
            "To validate our solution, we ran three algorithmic versions based on Logistic\n",
            "Regression, Linear Regression, and X2statistical tests. The first two algorithms\n",
            "were run with a variable workload on the benchmarking dataset ”Genome in a\n",
            "Bottle” [40]. The X2test was run against a synthetic dataset simulating 8 ∗105\n",
            "VCF files (one file per individual) with 1 ∗106random unique SNPs. The first two\n",
            "tests compare the performance impact of our solution against a baseline setup\n",
            "without any security guarantees. The third experiment is intended to evaluate\n",
            "the scalability, feasibility, and behavior of Gyosa with increasing servers.\n",
            "First, the results show that Gyosa does not affect the quality of the GWASes\n",
            "results. As expected, there is a trade-off between runtime computation and the\n",
            "level of privacy-preserving guarantees. Gyosa shows a runtime execution over-\n",
            "head ranging from 2 .5X forX2statistic tests to 10 Xon regression-based al-\n",
            "gorithms. Importantly, the results highlight that it is possible to effectively re-\n",
            "duce the computation runtime overhead by 2.7X times when distributing the\n",
            "computation across multiple nodes. Indeed, this is a key takeaway from this\n",
            "work, which shows that by distributing GWAS computations, one can achieve. CC-BY-NC-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted January 18, 2024. ; https://doi.org/10.1101/2024.01.15.575678doi: bioRxiv preprint\n"
          ]
        }
      ],
      "source": [
        "#  Install and setup LangChain\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Make sure you have the OPENAI API KEY set in your environment\n",
        "OpenAI.api_key = os.getenv('API_KEY')\n",
        "# <font color=blue> Load PDF file\n",
        "pdf_url = \"https://www.biorxiv.org/content/10.1101/2024.01.15.575678v2.full.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(pdf_url)\n",
        "\n",
        "pages = loader.load_and_split()\n",
        "#number of pages\n",
        "print(len(pages),'\\n')\n",
        "\n",
        "#view page content\n",
        "print(pages[3].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l58DSraxelzV",
        "outputId": "e05baa17-41e4-47ab-aed4-c75aa4e7e1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The paper introduces Gyosa, a distributed computing solution for privacy-preserving genome-wide association studies (GWAS). The solution uses trusted execution environments (TEEs) like Intel SGX to securely delegate GWAS analysis to untrusted third-party infrastructures. Gyosa allows for the handling of large amounts of genomic data in a scalable and efficient manner while protecting data privacy. The experimental evaluation shows that Gyosa provides enhanced security guarantees and can achieve practical and usable privacy-preserving solutions.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "##  Define the summarize pdf function\n",
        "# Define the main function that will take pdf file path as an input and generate a summary of the file.\n",
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap):\n",
        "\n",
        "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    #Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    #Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    #Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    #Summarize the chunks\n",
        "    # chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "    #Return the summary\n",
        "    return chain.run(docs_chunks)\n",
        "#print summary by using chain type stuff or map_reduce\n",
        "print(summarize_pdf(pdf_url, 1000, 20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIzJL2F6eo2t"
      },
      "outputs": [],
      "source": [
        "##  Add Prompt template to the summarizer function\n",
        "# Leveraging prompt templates to extract key information from the reserach paper in more guided manner.\n",
        "##  Define Prompt Templates\n",
        "map_prompt_template = \"\"\"\n",
        "                      Write a summary of the researh paper for a non-academic industry professional that includes main points and any important details in bullet points.{text}\n",
        "                      \"\"\"\n",
        "\n",
        "# below is the type of template that we can pass to llm, we can create according to the need and requirement\n",
        "# map_prompt_template =\"\"\" Writes a summary of the research paper for an IT professional to provide a technical overview  of the research topic in bullet point. {text} \"\"\"\n",
        "\n",
        "map_prompt = PromptTemplate(input_variables=[\"text\"], template=map_prompt_template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-_dB8W4j3NY",
        "outputId": "2fd38bbf-7fae-4acc-c303-c7670b3a9323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- The research paper introduces Gyosa, a distributed computing solution for privacy-preserving genome-wide association studies (GWAS).\n",
            "- Gyosa follows a distributed processing design that enables handling large amounts of genomic data in a scalable and efficient fashion.\n",
            "- It leverages trusted execution environments (TEEs), such as Intel SGX, to allow users to confidentially delegate their GWAS analysis to untrusted third-party infrastructures.\n",
            "- Gyosa implements a computation partitioning scheme to overcome the memory limitations of SGX while safeguarding users' genomic data privacy.\n",
            "- The experimental evaluation validates the applicability and scalability of Gyosa, showing that it provides enhanced security guarantees and a practical and usable privacy-preserving solution.\n",
            "- Gyosa is built on top of Apache Spark and uses the Glow library for genomic processing, allowing for the extension of the current genomic analysis pipeline.\n",
            "- The results show that Gyosa has a runtime overhead ranging from 2.5x to 10x compared to a baseline setup without security guarantees.\n",
            "- By distributing GWAS computations, Gyosa achieves a practical and usable privacy-preserving solution.\n",
            "- The paper provides a security analysis of Gyosa, highlighting its mechanisms for safeguarding users from attacks.\n",
            "- The performance and scalability analysis demonstrate that Gyosa can efficiently handle larger workloads and benefit from distributed computation across multiple servers.\n",
            "- Gyosa offers a cost-efficient alternative to high-end server setups by leveraging cloud environments for distributed computation.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# with stuff method  using map_prompt\n",
        "#Modify the custom function to add the prompt templates\n",
        "\n",
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, map_prompt):\n",
        "\n",
        "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    #Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    #Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    #Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    #Summarize the chunks\n",
        "    chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt = map_prompt)\n",
        "    #Return the summary\n",
        "    return chain.run(docs_chunks)\n",
        "#print summary by using combo prompts\n",
        "print(summarize_pdf(pdf_url, 1000, 20, map_prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-_jnkEieu5G",
        "outputId": "793dc1e8-4fcc-4fe4-f942-304dc82ac10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- The research paper introduces Gyosa, a distributed computing solution for privacy-preserving genome-wide association studies (GWAS).\n",
            "- Gyosa utilizes distributed processing and trusted execution environments (TEEs) to handle large amounts of genomic data while maintaining confidentiality.\n",
            "- The paper discusses the limitations of current solutions for data privacy protection in GWAS and proposes Gyosa as a more efficient and secure alternative.\n",
            "- Experimental evaluation confirms the applicability and scalability of Gyosa, demonstrating its ability to provide enhanced security guarantees.\n",
            "- The paper explores the challenges and vulnerabilities associated with offloading data storage and processing to third-party infrastructures and emphasizes the need for robust security measures.\n",
            "- The paper presents different frameworks and approaches, such as GWAS-Dist, GADE, and SOTERIA, for privacy-preserving solutions in GWAS.\n",
            "- The paper discusses various types of attacks on genomic data analysis and highlights the challenges and limitations of existing approaches for ensuring data privacy in GWAS.\n",
            "- The paper proposes trusted execution environments (TEEs) as alternative solutions to ensure privacy and presents frameworks that utilize secure multi-party computation (MPC) protocols.\n",
            "- The paper emphasizes the importance of addressing the security and privacy concerns associated with storing and processing genomic data in untrusted infrastructures.\n",
            "- The research paper evaluates the impact of Gyosa on the quality and runtime of GWASes and demonstrates that Gyosa does not affect the quality of the GWASes.\n",
            "- The runtime execution overhead of Gyosa ranges from 2.5X to 10X, but distributing the computation across multiple nodes can effectively reduce the runtime overhead.\n",
            "- The paper discusses the architecture and components of Gyosa, including secure and non-secure workers, encryption modules, and a distributed storage system.\n",
            "- Mitigation strategies, such as encryption protocols and the use of virtual private networks (VPNs), are recommended to enhance data security.\n",
            "- The paper presents other related solutions and frameworks, such as Privgendb, Varys, and Drynx, for privacy-preserving genomic analysis and secure statistical queries.\n",
            "- The paper discusses the challenges of balancing security and privacy in genomic data and proposes solutions.\n",
            "- The paper references other relevant studies and papers in the field of genomics and data privacy.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# with map_reduce method\n",
        "combine_prompt_template = \"\"\"you will be given main points and any important details of a research paper in bullet points.\n",
        "                             you goal is to give a final summary of the main research topic and findings which will be useful to a researcher to grasp\n",
        "                             what was done during the research work.\n",
        "\n",
        "'''{text}'''\n",
        "FINAL SUMMARY:\n",
        "\"\"\"\n",
        "\n",
        "combine_prompt = PromptTemplate(input_variables=[\"text\"], template=combine_prompt_template)\n",
        "#Modify the custom function to add the prompt templates\n",
        "\n",
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, map_prompt, combine_prompt):\n",
        "\n",
        "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    #Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    #Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    #Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    #Summarize the chunks\n",
        "\n",
        "    # chain = load_summarize_chain(llm, chain_type=\"map_reduce\", prompt = map_prompt)\n",
        "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt = map_prompt, combine_prompt = combine_prompt)\n",
        "    #Return the summary\n",
        "    return chain.run(docs_chunks)\n",
        "\n",
        "#print summary by using combo prompts\n",
        "print(summarize_pdf(pdf_url, 1000, 20, map_prompt, combine_prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niVvRuv9ezE9",
        "outputId": "1a855569-36d3-4cb9-cb1a-b4109c35f251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "##  Build and test a GenAI app for PDF summarization\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Make sure you have the OPENAI API KEY set in your environment\n",
        "OpenAI.api_key = os.getenv('API_KEY')\n",
        "\n",
        "#summarize_pdf function\n",
        "\n",
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, prompt):\n",
        "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    #Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    #Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    #Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    #Summarize the chunks\n",
        "    chain = load_summarize_chain(llm, chain_type='stuff', prompt = prompt)\n",
        "\n",
        "    #Return the summary\n",
        "    summary= chain.invoke(docs_chunks, return_only_outputs=True)\n",
        "    return summary[\"output_text\"]\n",
        "\n",
        "#streamlit app main() function\n",
        "\n",
        "def main():\n",
        "    #Set page config and title\n",
        "    st.set_page_config(page_title=\"PDF Summarizer\", page_icon=\":book:\", layout=\"wide\")\n",
        "    st.title(\"PDF Summarizer\")\n",
        "\n",
        "    #Input pdf file path\n",
        "    pdf_file_path = st.text_input(\"Enter PDF file path:\")\n",
        "    if pdf_file_path != \"\":\n",
        "        st.write(\"PDF file was loaded successfully\")\n",
        "\n",
        "    #Prompt input\n",
        "    user_prompt = st.text_input(\"Enter prompt:\")\n",
        "    user_prompt = user_prompt + \"\"\":\\n\\n {text}\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"text\"], template=user_prompt)\n",
        "\n",
        "    #Summarize button\n",
        "    if st.button(\"Summarize\"):\n",
        "        #Summarize pdf\n",
        "        summary = summarize_pdf(pdf_file_path, 1000, 20, prompt)\n",
        "        st.write(summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK49i6BDe7aM",
        "outputId": "d54066ad-83d0-450d-89d1-9233c9d62558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "##  Cumulative Activity\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Make sure you have the OPENAI API KEY set in your environment\n",
        "OpenAI.api_key = os.getenv('API_KEY')\n",
        "\n",
        "#summarize_pdf function\n",
        "\n",
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, chain_type, prompt):\n",
        "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    #Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    #Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    #Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    #Create multiple prompts\n",
        "    prompt = prompt + \"\"\":\\n\\n {text}\"\"\"\n",
        "    combine_prompt = PromptTemplate(input_variables=[\"text\"], template=prompt)\n",
        "    map_prompt = PromptTemplate(template=\"Summarize:\\n\\n{text}\", input_variables=[\"text\"])\n",
        "\n",
        "    #Summarize the chunks\n",
        "    if chain_type == \"map_reduce\":\n",
        "        chain = load_summarize_chain(llm, chain_type=chain_type,\n",
        "                                    map_prompt=map_prompt, combine_prompt=combine_prompt)\n",
        "    else:\n",
        "        chain = load_summarize_chain(llm, chain_type= chain_type, prompt=combine_prompt)\n",
        "    #Return the summary\n",
        "    return chain.run(docs_chunks)\n",
        "\n",
        "#streamlit app main() function\n",
        "\n",
        "def main():\n",
        "    #Set page config and title\n",
        "    st.set_page_config(page_title=\"GenAI App\", page_icon=\":book:\", layout=\"wide\")\n",
        "    st.title(\"PDF Summarizer\")\n",
        "\n",
        "    #Add custom sliders and selectbox for more user interaction\n",
        "    chain_type = st.sidebar.selectbox(\"Chain Type\", [\"map_reduce\", \"stuff\"])\n",
        "    chunk_size = st.sidebar.slider(\"Chunk Size\", min_value=100, max_value=10000, step=100, value=1900)\n",
        "    chunk_overlap = st.sidebar.slider(\"Chunk Overlap\", min_value=100, max_value=10000, step=100, value=200)\n",
        "\n",
        "    #display warning message\n",
        "    if 'map_reduce' in chain_type:\n",
        "      st.sidebar.warning(f'Map_reduce chain type takes more than 5 mins to generate summary due to prompt latency!')\n",
        "\n",
        "    #Input pdf file path\n",
        "    pdf_file_path = st.text_input(\"Enter PDF file path:\")\n",
        "\n",
        "    #Prompt input\n",
        "    user_prompt = st.text_input(\"Enter prompt:\")\n",
        "\n",
        "    #Summarize button\n",
        "    if st.button(\"Summarize\"):\n",
        "        #Summarize pdf\n",
        "        summary = summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, chain_type, user_prompt)\n",
        "        st.write(summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flXUZA9QrmQQ",
        "outputId": "51ca09ec-8a31-470d-9797-4fa3bbcfca22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-24 14:38:27--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.237.133.81, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.28M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-06-24 14:38:27 (209 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Launch Streamlit app from Google Colab\n",
        "\n",
        "# The following lines of code would enable users to launch Streamlit app from Google Colab using [ngrok service](https://ngrok.com/)\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJFva7xhrpAu",
        "outputId": "3f929e51-fe5c-4dd8-e4bc-7750a285af6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ],
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_7DHY77rrKv"
      },
      "outputs": [],
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_UZD5Rxrsd5",
        "outputId": "01e7f2c1-838f-494c-c8d0-c818c722e358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.48.95.8\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiodwPGMrtb2",
        "outputId": "9c205e67-f17e-42c6-c4f3-c1d61fb975fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.48.95.8:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.417s\n",
            "your url is: https://eight-planets-lead.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:29: UserWarning: Importing OpenAI from langchain root module is no longer supported. Please use langchain_community.llms.OpenAI instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing PyPDFLoader from langchain.document_loaders is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.document_loaders import PyPDFLoader\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.document_loaders import PyPDFLoader\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here https://python.langchain.com/v0.2/docs/versions/v0_2/ \n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:29: UserWarning: Importing OpenAI from langchain root module is no longer supported. Please use langchain_community.llms.OpenAI instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:29: UserWarning: Importing OpenAI from langchain root module is no longer supported. Please use langchain_community.llms.OpenAI instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing PyPDFLoader from langchain.document_loaders is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.document_loaders import PyPDFLoader\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.document_loaders import PyPDFLoader\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here https://python.langchain.com/v0.2/docs/versions/v0_2/ \n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
